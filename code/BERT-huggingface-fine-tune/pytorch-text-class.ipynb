{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"source":["# 0. 环境\n","kaggle 里面创建的 Notebook， GPU 也是官方免费给的 Tesla P100 16GB 显存。\n","# 1. 定义数据集"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-06-19T12:22:55.595372Z","iopub.status.busy":"2022-06-19T12:22:55.594546Z","iopub.status.idle":"2022-06-19T12:23:16.468141Z","shell.execute_reply":"2022-06-19T12:23:16.465787Z","shell.execute_reply.started":"2022-06-19T12:22:55.595280Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d4c64b0faef4e90b88a48a9298afc9a","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/1.88k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset chn_senti_corp/default to /root/.cache/huggingface/datasets/seamew___chn_senti_corp/default/0.0.0/1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c41c0c6a1dd4f7a9a3a91e778f0d0cb","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/3.03M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fbdb74e001fd4227a9306dd89df06822","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/376k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"181cb987f9db464d8dc8d9e77ffbff29","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/371k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Generating validation split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Generating test split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset chn_senti_corp downloaded and prepared to /root/.cache/huggingface/datasets/seamew___chn_senti_corp/default/0.0.0/1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85. Subsequent calls will reuse this data.\n"]},{"data":{"text/plain":["(9600,\n"," ('选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般',\n","  1))"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","from datasets import load_dataset\n","\n","# 固定随机种子，实验可重复\n","seed = 42\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = True\n","\n","\n","#定义数据集\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, split):\n","        self.dataset = load_dataset(path='seamew/ChnSentiCorp', split=split)\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, i):\n","        text = self.dataset[i]['text']\n","        label = self.dataset[i]['label']\n","\n","        return text, label\n","\n","\n","dataset = Dataset('train')\n","\n","len(dataset), dataset[0]"]},{"cell_type":"markdown","metadata":{},"source":["训练集共 9600 句话，以第一个样本为例，评价为差评。"]},{"cell_type":"markdown","metadata":{},"source":["# 2. 加载 tokenizer"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-06-19T12:23:16.471570Z","iopub.status.busy":"2022-06-19T12:23:16.470535Z","iopub.status.idle":"2022-06-19T12:23:20.809037Z","shell.execute_reply":"2022-06-19T12:23:20.807725Z","shell.execute_reply.started":"2022-06-19T12:23:16.471522Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1c84cb3f3844f3eb49517276280bba0","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/107k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"36b5e2e3e03c46338045b57293b78278","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3434c0cf7a354345b95658af01e0cf85","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/624 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["PreTrainedTokenizer(name_or_path='bert-base-chinese', vocab_size=21128, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import BertTokenizer\n","\n","#加载字典和分词工具\n","token = BertTokenizer.from_pretrained('bert-base-chinese')\n","\n","token"]},{"cell_type":"markdown","metadata":{},"source":["## 3. 定义批处理函数\n","该函数中进行分词和编码"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-06-19T12:23:20.811239Z","iopub.status.busy":"2022-06-19T12:23:20.810686Z","iopub.status.idle":"2022-06-19T12:23:20.820857Z","shell.execute_reply":"2022-06-19T12:23:20.819146Z","shell.execute_reply.started":"2022-06-19T12:23:20.811192Z"},"trusted":true},"outputs":[],"source":["def collate_fn(data):\n","    sents = [i[0] for i in data]\n","    labels = [i[1] for i in data]\n","\n","    #编码\n","    data = token.batch_encode_plus(batch_text_or_text_pairs=sents,\n","                                   truncation=True,\n","                                   padding='max_length',\n","                                   max_length=500,\n","                                   return_tensors='pt',\n","                                   return_length=True)\n","\n","    #input_ids:编码之后的数字\n","    #attention_mask:是补零的位置是0,其他位置是1\n","    input_ids = data['input_ids']\n","    attention_mask = data['attention_mask']\n","    token_type_ids = data['token_type_ids']\n","    labels = torch.LongTensor(labels)\n","\n","    #print(data['length'], data['length'].max())\n","\n","    return input_ids, attention_mask, token_type_ids, labels"]},{"cell_type":"markdown","metadata":{},"source":["# 4. 定义数据加载器并查看数据样例"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-06-19T12:23:20.825102Z","iopub.status.busy":"2022-06-19T12:23:20.824364Z","iopub.status.idle":"2022-06-19T12:23:20.878643Z","shell.execute_reply":"2022-06-19T12:23:20.877437Z","shell.execute_reply.started":"2022-06-19T12:23:20.825056Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["600\n"]},{"data":{"text/plain":["(torch.Size([16, 500]),\n"," torch.Size([16, 500]),\n"," torch.Size([16, 500]),\n"," tensor([0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1]))"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["#数据加载器\n","loader = torch.utils.data.DataLoader(dataset=dataset,\n","                                     batch_size=16,\n","                                     collate_fn=collate_fn,\n","                                     shuffle=True,\n","                                     drop_last=True)\n","\n","for i, (input_ids, attention_mask, token_type_ids,\n","        labels) in enumerate(loader):\n","    break\n","\n","print(len(loader))\n","input_ids.shape, attention_mask.shape, token_type_ids.shape, labels"]},{"cell_type":"markdown","metadata":{},"source":["# 5. 加载 BERT 中文预训练模型"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-06-19T12:23:20.881317Z","iopub.status.busy":"2022-06-19T12:23:20.880576Z","iopub.status.idle":"2022-06-19T12:24:14.173392Z","shell.execute_reply":"2022-06-19T12:24:14.172261Z","shell.execute_reply.started":"2022-06-19T12:23:20.881272Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b949f6fcf2984603a3eb3a304a4afb6c","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/393M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"text/plain":["torch.Size([16, 500, 768])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import BertModel\n","\n","#加载预训练模型\n","pretrained = BertModel.from_pretrained('bert-base-chinese')\n","\n","#不冻结预训练模型的参数\n","for param in pretrained.parameters():\n","    param.requires_grad_(True)\n","\n","#模型试算\n","out = pretrained(input_ids=input_ids,\n","           attention_mask=attention_mask,\n","           token_type_ids=token_type_ids)\n","\n","out.last_hidden_state.shape"]},{"cell_type":"markdown","metadata":{},"source":["16 表示 batch_size，表示 16 句话，\n","\n","500 表示数据分词的一个长度，数据编码时，指定每一句话编码成 500 个词的长度，\n","\n","768 是词编码的维度，把每一个词编码成一个 768 维的向量"]},{"cell_type":"markdown","metadata":{},"source":["# 6. 定义下游任务模型\n","只包含一个单全连接层，对应二分类"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-06-19T12:24:14.176133Z","iopub.status.busy":"2022-06-19T12:24:14.175014Z","iopub.status.idle":"2022-06-19T12:24:50.209920Z","shell.execute_reply":"2022-06-19T12:24:50.208616Z","shell.execute_reply.started":"2022-06-19T12:24:14.176088Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([16, 2])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["#定义下游任务模型\n","class Model(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.fc = torch.nn.Linear(768, 2)\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        with torch.no_grad():\n","            out = pretrained(input_ids=input_ids,\n","                       attention_mask=attention_mask,\n","                       token_type_ids=token_type_ids)\n","        # 0 表示 cls 位，使用 cls 进行分类任务\n","        out = self.fc(out.last_hidden_state[:, 0])\n","\n","        out = out.softmax(dim=1)\n","\n","        return out\n","\n","\n","model = Model()\n","    \n","model(input_ids=input_ids,\n","      attention_mask=attention_mask,\n","      token_type_ids=token_type_ids).shape"]},{"cell_type":"markdown","metadata":{},"source":["# 7. 训练下游任务"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-06-19T12:24:50.212626Z","iopub.status.busy":"2022-06-19T12:24:50.211461Z","iopub.status.idle":"2022-06-19T12:26:17.892039Z","shell.execute_reply":"2022-06-19T12:26:17.889989Z","shell.execute_reply.started":"2022-06-19T12:24:50.212575Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]},{"name":"stdout","output_type":"stream","text":["0 0.6742366552352905 0.5625\n","5 0.7023376226425171 0.5\n","10 0.6331156492233276 0.625\n","15 0.7474691867828369 0.375\n","20 0.5797390937805176 0.6875\n","25 0.5568404793739319 0.9375\n","30 0.6012440323829651 0.875\n","35 0.6725104451179504 0.5625\n","40 0.539483904838562 0.875\n","45 0.5475109815597534 0.875\n","50 0.5602291822433472 0.875\n","55 0.5149505138397217 0.9375\n","60 0.5647078156471252 0.8125\n","65 0.538317859172821 0.75\n","70 0.5270556211471558 0.875\n","75 0.520484983921051 0.8125\n","80 0.46829140186309814 0.875\n","85 0.5209758877754211 0.8125\n","90 0.5698109865188599 0.6875\n","95 0.49698641896247864 0.875\n","100 0.6128743290901184 0.625\n","105 0.4816654920578003 0.875\n","110 0.47260743379592896 1.0\n","115 0.6126810908317566 0.6875\n","120 0.4164586067199707 1.0\n","125 0.5309047698974609 0.75\n","130 0.543803870677948 0.6875\n","135 0.4575423300266266 0.875\n","140 0.5235946774482727 0.8125\n","145 0.43342381715774536 0.9375\n","150 0.3835070729255676 1.0\n","155 0.4110313653945923 1.0\n","160 0.40721094608306885 0.9375\n","165 0.4661119282245636 0.9375\n","170 0.48450756072998047 0.875\n","175 0.3964672386646271 0.9375\n","180 0.4071957767009735 0.9375\n","185 0.3777785897254944 1.0\n","190 0.4967274069786072 0.875\n","195 0.4978007972240448 0.8125\n","200 0.43165770173072815 0.875\n","205 0.615345299243927 0.75\n","210 0.41679057478904724 0.875\n","215 0.4014279544353485 1.0\n","220 0.5179368257522583 0.75\n","225 0.41985660791397095 0.875\n","230 0.43277302384376526 0.9375\n","235 0.501972496509552 0.8125\n","240 0.4389626085758209 0.875\n","245 0.44646528363227844 0.875\n","250 0.45368289947509766 0.875\n","255 0.37346020340919495 1.0\n","260 0.4270491600036621 0.875\n","265 0.45540279150009155 0.9375\n","270 0.36886194348335266 0.9375\n","275 0.44774380326271057 0.875\n","280 0.4400089681148529 0.9375\n","285 0.42821288108825684 0.875\n","290 0.415386438369751 0.9375\n","295 0.44775474071502686 0.8125\n","300 0.513365626335144 0.75\n","训练时间： 87.64389634132385\n"]}],"source":["from transformers import AdamW\n","import time\n","\n","start = time.time()\n","#训练\n","optimizer = AdamW(model.parameters(), lr=5e-4)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","if torch.cuda.is_available():\n","    pretrained = pretrained.cuda()\n","    model = model.cuda()   \n","    criterion = criterion.cuda()\n","    \n","model.train()\n","for i, (input_ids, attention_mask, token_type_ids,\n","        labels) in enumerate(loader):\n","    if torch.cuda.is_available():\n","        input_ids, attention_mask, token_type_ids, labels = input_ids.cuda(), attention_mask.cuda(), token_type_ids.cuda(), labels.cuda() \n","        \n","    out = model(input_ids=input_ids,\n","                attention_mask=attention_mask, \n","                token_type_ids=token_type_ids)\n","    \n","    loss = criterion(out, labels)\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","\n","    if i % 5 == 0:\n","        out = out.argmax(dim=1)\n","        accuracy = (out == labels).sum().item() / len(labels)\n","\n","        print(i, loss.item(), accuracy)\n","\n","    if i == 300:\n","        break\n","end = time.time()\n","print('训练时间：', end - start)"]},{"cell_type":"markdown","metadata":{},"source":["# 8. 测试"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-06-19T12:26:17.895741Z","iopub.status.busy":"2022-06-19T12:26:17.895109Z","iopub.status.idle":"2022-06-19T12:26:40.261044Z","shell.execute_reply":"2022-06-19T12:26:40.259709Z","shell.execute_reply.started":"2022-06-19T12:26:17.895666Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","0.8699324324324325\n"]}],"source":["#测试\n","def test():\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    loader_test = torch.utils.data.DataLoader(dataset=Dataset('validation'),\n","                                              batch_size=32,\n","                                              collate_fn=collate_fn,\n","                                              shuffle=False,\n","                                              drop_last=True)\n","\n","    for i, (input_ids, attention_mask, token_type_ids,\n","            labels) in enumerate(loader_test):\n","        if torch.cuda.is_available():\n","            input_ids, attention_mask, token_type_ids, labels = input_ids.cuda(), attention_mask.cuda(), token_type_ids.cuda(), labels.cuda()\n","        \n","#         if i == 5:\n","#             break\n","\n","        print(i)\n","\n","        with torch.no_grad():\n","            out = model(input_ids=input_ids,\n","                        attention_mask=attention_mask,\n","                        token_type_ids=token_type_ids)\n","\n","        out = out.argmax(dim=1)\n","        correct += (out == labels).sum().item()\n","        total += len(labels)\n","\n","    print(correct / total)\n","\n","test()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-06-19T12:26:40.263832Z","iopub.status.busy":"2022-06-19T12:26:40.262620Z","iopub.status.idle":"2022-06-19T12:26:41.209866Z","shell.execute_reply":"2022-06-19T12:26:41.208552Z","shell.execute_reply.started":"2022-06-19T12:26:40.263781Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Sun Jun 19 12:26:41 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   70C    P0    51W / 250W |   2893MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-06-19T12:26:41.214576Z","iopub.status.busy":"2022-06-19T12:26:41.213720Z","iopub.status.idle":"2022-06-19T12:26:41.225026Z","shell.execute_reply":"2022-06-19T12:26:41.223993Z","shell.execute_reply.started":"2022-06-19T12:26:41.214506Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'1.11.0'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["torch.__version__"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
